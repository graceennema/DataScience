{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11: Model Selection, Regularized regression and final practice\n",
    "## Learning goals \n",
    "This homework includes some repeated task and variations on model fitting, and model comparision, which should prepare you optimally for the final. \n",
    "The homework also introduces z-standardization and regularized (L2) regression. \n",
    "Try to solve the task in the homework independently, and prepare a cheat-sheet and a file with useful functions, such that you can complete this homework in 3 hrs or less. \n",
    "\n",
    "## Data set \n",
    "The file kaiser.csv contains a subset of data from the Child Health and Development Studies, which investigate a range of topics. One study considered all pregnancies between 1960 and 1967 among women in the Kaiser Foundation Health Plan in the San Francisco East Bay area. Here, we look at the predictor of birth weight of babies, measured in pounds, as well as the occurence of complications in the first 3 month. \n",
    "\n",
    "The data frame stored in babies.csv contains the variables: \n",
    "- gestation:    Gestation period (length of pregnancy) [days]\n",
    "- parity:       1: child the first born 0: Child has older siblings \n",
    "- age:          Age of the mom at time of birth\n",
    "- height:       Height of the baby [cm].\n",
    "- weight:       Weight of the baby [pounds].  \n",
    "- smoke:        Is the mom a smoker / non-smoker? \n",
    "- hospital:     Which hospital was the birth at? Oakland, SanFrancisco, WalnutCreek, SanJose, and Richmond.\n",
    "- complication: Was there a complication within the first 3 month of pregnancy (0: No 1:Yes) \n",
    "\n",
    "## Preliminaries\n",
    "Set up the environment by importing pandas, seaborn, numpy, scipy.optimize and matplotlib. \n",
    "Then add your multiple regression functions (multRegPredict,multRegLossRSS, multRegFit) from the last homeworks. \n",
    "\n",
    "To make it easier - we have done these things already! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.optimize as so\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multRegPredict(b,D,xname):\n",
    "    \"\"\"Prediction function for multipel regression \n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "\n",
    "    Returns:\n",
    "        yp (nd.array): Predicted y - values \n",
    "    \"\"\"\n",
    "    yp=np.ones(len(D.index))*b[0]        # Intercept \n",
    "    for i in range(len(xname)):          \n",
    "        yp=yp+D[xname[i]]*b[i+1]         # Add each regression value \n",
    "    return yp \n",
    "\n",
    "def multRegLossRSS(b,D,y,xname):\n",
    "    \"\"\"Loss function for OLS multiple regression \n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "\n",
    "    Returns:\n",
    "        rss: Current loss\n",
    "        grad: gradient of loss function in respect to parameters  \n",
    "    \"\"\"\n",
    "    predY = multRegPredict(b,D,xname)\n",
    "    res = y-predY\n",
    "    rss = sum(res**2)\n",
    "    grad=np.zeros(len(b))\n",
    "    grad[0]=-2*np.sum(res)\n",
    "    for i in range(len(xname)):\n",
    "        grad[i+1]=-2*np.sum(D[xname[i]]*res)\n",
    "    return (rss,grad)\n",
    "\n",
    "def multRegFit(D,y,xname=[],figure=0,b0=[]):\n",
    "    \"\"\"Fits a multiple regression loss function \n",
    "\n",
    "    Args:\n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables  \n",
    "        figure (int): Plot figure? Defaults to 0.\n",
    "        b0 (np.ndarray). Initial guess for the parameter vector\n",
    "\n",
    "    Returns:\n",
    "        R2: Fitted R2 value \n",
    "        b: Fitted \n",
    "    \"\"\"\n",
    "    k=len(xname)+1\n",
    "    if (len(b0)!=k):\n",
    "        b0=np.zeros((k,))\n",
    "    RES = so.minimize(multRegLossRSS,b0,args=(D,y,xname),jac=True)\n",
    "    b=RES.x # Results\n",
    "    res = y-np.mean(y)\n",
    "    TSS = sum(res**2)\n",
    "    RSS,deriv = multRegLossRSS(b,D,y,xname)\n",
    "    R2 = 1-RSS/TSS \n",
    "    if (k==2 and figure==1):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(D[xname[0]],y)\n",
    "        xRange=[min(D[xname[0]]),max(D[xname[0]])]\n",
    "        xp=np.arange(xRange[0],xRange[1],(xRange[1]-xRange[0])/50)\n",
    "        yp=b[0]+b[1]*xp\n",
    "        ax.plot(xp,yp,'r-')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    return (R2,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>smoke</th>\n",
       "      <th>hospital</th>\n",
       "      <th>gestation</th>\n",
       "      <th>parity</th>\n",
       "      <th>weight</th>\n",
       "      <th>complication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.945386</td>\n",
       "      <td>smoker</td>\n",
       "      <td>WalnutCreek</td>\n",
       "      <td>259.984898</td>\n",
       "      <td>1</td>\n",
       "      <td>6.154760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.369146</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanFrancisco</td>\n",
       "      <td>279.583370</td>\n",
       "      <td>0</td>\n",
       "      <td>6.746684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.932707</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>287.107287</td>\n",
       "      <td>0</td>\n",
       "      <td>9.150785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.791652</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>270.374191</td>\n",
       "      <td>0</td>\n",
       "      <td>7.023815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.950210</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>245.130005</td>\n",
       "      <td>0</td>\n",
       "      <td>5.861300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17.535064</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.054332</td>\n",
       "      <td>1</td>\n",
       "      <td>6.816188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>36.919301</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>249.503172</td>\n",
       "      <td>0</td>\n",
       "      <td>6.355362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>29.618348</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.715985</td>\n",
       "      <td>1</td>\n",
       "      <td>6.102431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>22.833492</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>288.755560</td>\n",
       "      <td>0</td>\n",
       "      <td>6.926468</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>26.797815</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>286.339453</td>\n",
       "      <td>0</td>\n",
       "      <td>10.115025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       smoke      hospital   gestation  parity     weight  \\\n",
       "0   28.945386      smoker   WalnutCreek  259.984898       1   6.154760   \n",
       "1   37.369146  non-smoker  SanFrancisco  279.583370       0   6.746684   \n",
       "2   34.932707  non-smoker      Richmond  287.107287       0   9.150785   \n",
       "3   34.791652  non-smoker       Oakland  270.374191       0   7.023815   \n",
       "4   41.950210  non-smoker       SanJose  245.130005       0   5.861300   \n",
       "..        ...         ...           ...         ...     ...        ...   \n",
       "95  17.535064      smoker      Richmond  264.054332       1   6.816188   \n",
       "96  36.919301  non-smoker      Richmond  249.503172       0   6.355362   \n",
       "97  29.618348      smoker      Richmond  264.715985       1   6.102431   \n",
       "98  22.833492  non-smoker       SanJose  288.755560       0   6.926468   \n",
       "99  26.797815  non-smoker       Oakland  286.339453       0  10.115025   \n",
       "\n",
       "    complication  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "..           ...  \n",
       "95             1  \n",
       "96             0  \n",
       "97             0  \n",
       "98             1  \n",
       "99             0  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"kaiser.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Multiple regression with discrete variables ( / 30 pts)\n",
    "### Question 1.1 ( / 10pt)\n",
    "Create a dummy variable for Smoker / Non-smoker. Set the value for “Smoker” to 1 and for “Non-smoker” to 0. Estimate a regression model with the dummy variable as a regressor *and birth weight as the response variable.* \n",
    "\n",
    "Report the value of the intercept and slope. What does the intercept and slope value indicate? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>smoke</th>\n",
       "      <th>hospital</th>\n",
       "      <th>gestation</th>\n",
       "      <th>parity</th>\n",
       "      <th>weight</th>\n",
       "      <th>complication</th>\n",
       "      <th>dSmoke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.945386</td>\n",
       "      <td>smoker</td>\n",
       "      <td>WalnutCreek</td>\n",
       "      <td>259.984898</td>\n",
       "      <td>1</td>\n",
       "      <td>6.154760</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.369146</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanFrancisco</td>\n",
       "      <td>279.583370</td>\n",
       "      <td>0</td>\n",
       "      <td>6.746684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.932707</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>287.107287</td>\n",
       "      <td>0</td>\n",
       "      <td>9.150785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.791652</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>270.374191</td>\n",
       "      <td>0</td>\n",
       "      <td>7.023815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.950210</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>245.130005</td>\n",
       "      <td>0</td>\n",
       "      <td>5.861300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17.535064</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.054332</td>\n",
       "      <td>1</td>\n",
       "      <td>6.816188</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>36.919301</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>249.503172</td>\n",
       "      <td>0</td>\n",
       "      <td>6.355362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>29.618348</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.715985</td>\n",
       "      <td>1</td>\n",
       "      <td>6.102431</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>22.833492</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>288.755560</td>\n",
       "      <td>0</td>\n",
       "      <td>6.926468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>26.797815</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>286.339453</td>\n",
       "      <td>0</td>\n",
       "      <td>10.115025</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       smoke      hospital   gestation  parity     weight  \\\n",
       "0   28.945386      smoker   WalnutCreek  259.984898       1   6.154760   \n",
       "1   37.369146  non-smoker  SanFrancisco  279.583370       0   6.746684   \n",
       "2   34.932707  non-smoker      Richmond  287.107287       0   9.150785   \n",
       "3   34.791652  non-smoker       Oakland  270.374191       0   7.023815   \n",
       "4   41.950210  non-smoker       SanJose  245.130005       0   5.861300   \n",
       "..        ...         ...           ...         ...     ...        ...   \n",
       "95  17.535064      smoker      Richmond  264.054332       1   6.816188   \n",
       "96  36.919301  non-smoker      Richmond  249.503172       0   6.355362   \n",
       "97  29.618348      smoker      Richmond  264.715985       1   6.102431   \n",
       "98  22.833492  non-smoker       SanJose  288.755560       0   6.926468   \n",
       "99  26.797815  non-smoker       Oakland  286.339453       0  10.115025   \n",
       "\n",
       "    complication  dSmoke  \n",
       "0              1     1.0  \n",
       "1              1     0.0  \n",
       "2              0     0.0  \n",
       "3              0     0.0  \n",
       "4              0     0.0  \n",
       "..           ...     ...  \n",
       "95             1     1.0  \n",
       "96             0     0.0  \n",
       "97             0     1.0  \n",
       "98             1     0.0  \n",
       "99             0     0.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dSmoke = df['smoke'] == 'smoker'\n",
    "dSmoke = np.double(dSmoke)\n",
    "df['dSmoke']  = dSmoke\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 is 0.17730888763721242\n",
      "The b values are [ 7.68827818 -1.20831337]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "R2, b = multRegFit(df,y = df[\"weight\"], xname=[\"dSmoke\"],figure=1,b0=[])\n",
    "print(\"The R2 is\", R2)\n",
    "print(\"The b values are\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 1. Scatter plot of smoker status against birth weight. 0 is for non-smoker and 1 is for smoker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept represents the mean birthweight of non-smoke and the slope is the difference between non-smokers and smokes. The trend is that birthweight for babies born to smokers is lower than non-smokers. This is shown through the negative slope (decreasing). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.2 ( / 8pt)\n",
    "Make a boxplot of hospital on the x-axis and birthweight on the y-axis (see HW2 for an example). Which hospital has the lowest overall birth weight?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Hospital')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(figsize = (10,5))\n",
    "sns.boxplot(data = df, y = \"weight\", x = \"hospital\", ax = axes, color = \"m\")\n",
    "axes.set_ylabel(\"birthweight\")\n",
    "axes.set_xlabel(\"Hospital\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure 2. Boxplot of birthweight by hospital. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hospital that has the lowest average birthweight is Oakland, however, Richmonds IQR extends the lowest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1.3  ( / 12pt)\n",
    "Create a set of 4 dummy variables that together code the hospital. Set Walnut Creek to be your comparison group. Run a multiple regression model with the 4 dummy variables as explanatory variables. Report the interecept and slope values. What do the intercept and slope values mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The R2 is 0.017073994697972106\n",
      "The b values are [ 7.64577979  0.02134188 -0.33250686 -0.2043533  -0.10127978]\n"
     ]
    }
   ],
   "source": [
    "# dWC = df['hospital'] == 'WalnutCreek'\n",
    "# dWC = np.double(dWC)\n",
    "# df['dWC']  = dWC\n",
    "\n",
    "dSF = df['hospital'] == 'SanFrancisco'\n",
    "dSF = np.double(dSF)\n",
    "df['dSF']  = dSF\n",
    "\n",
    "dRich = df['hospital'] == 'Richmond'\n",
    "dRich = np.double(dRich)\n",
    "df['dRich']  = dRich\n",
    "\n",
    "dOak = df['hospital'] == 'Oakland'\n",
    "dOak = np.double(dOak)\n",
    "df['dOak']  = dOak\n",
    "\n",
    "dSJ = df['hospital'] == 'SanJose'\n",
    "dSJ = np.double(dSJ)\n",
    "df['dSJ']  = dSJ\n",
    "\n",
    "R2, b = multRegFit(df,y = df[\"weight\"], xname=[\"dSF\", \"dRich\", \"dOak\", \"dSJ\"],figure=1,b0=[])\n",
    "print(\"The R2 is\", R2)\n",
    "print(\"The b values are\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercept is representative of the mean of Walnut Creek as it is playing the role of the comparison group. The slopes are the differences between each hospital. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Model selection for multiple regression  ( / 35 pts)\n",
    "### Question 2.1 ( / 20 pts)\n",
    "Write a version of the crossvalidation function that does K-fold crossvalidation and works specifically with multRegFit as the fitting function. \n",
    "\n",
    "KfoldCVmultReg(D,y,xname,K=20,fitfcn=multRegFit,param={},predictfcn=multRegPredict):\n",
    "- D: Data Frame with explanatory variables  \n",
    "- y: response variable \n",
    "- xname: List of explanatory variables\n",
    "- K: Number of crossvalidation folds\n",
    "\n",
    "For dividing the data up in K pieces, you can use the following trick to assign a partition index to each of the data-points:\n",
    "```\n",
    "#N = number of data points \n",
    "#K = number of test sets (folds)\n",
    "ind = np.arange(N)\n",
    "ind = np.floor(ind/N*K)\n",
    "```\n",
    "\n",
    "\n",
    "The code should compute and return the crossvalidated R2 and the fitted R2. \n",
    "It should use the entries in the Dictionary to pass them to the function using `fitfcn(D,y,xname,**param)`\n",
    "Run 20-fold crossvalidation on the multiple regression model, with birth weight as the response variable and \n",
    "\n",
    "- age of the mother \n",
    "- smoker (dummy coded) \n",
    "- birth occurred in Oakland? \n",
    "- gestation \n",
    "\n",
    "as explanatory variables. \n",
    "Report R2cv and R2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCVmultReg(D, y, xname, K = 20, fitfcn = multRegFit, param={}, predfcn = multRegPredict):\n",
    "\n",
    "    # first create an array that represent the index \n",
    "    ind = np.arange(len(df.index))\n",
    "    \n",
    "    yp_cv = np.zeros(len(df.index))\n",
    "\n",
    "    # use np.array_split to generate indices for folds\n",
    "    folds = np.array_split(ind, K)\n",
    "    \n",
    "    N = len(folds)\n",
    "    \n",
    "    r,b0 = fitfcn(D,y,xname,**param)\n",
    "    \n",
    "    for f in np.arange(N): \n",
    "        folds_cp = folds.copy() # creating a copy of the folds array\n",
    "        test_ind = folds[f] # get the indices for test set\n",
    "        df_test  = df.loc[test_ind] # set one fold aside for testing\n",
    "\n",
    "\n",
    "        del folds_cp[f]        # delete the test set indices\n",
    "        train_ind = np.concatenate(folds_cp, axis = 0) # concatenate all the remaining indices into 1 array\n",
    "        df_train  = df.loc[train_ind]\n",
    "        ytrain = y.loc[train_ind]\n",
    "        \n",
    "        r,b = fitfcn(df_train,ytrain,xname,**param) # multRegFit(D,y,xname=[],figure=0,b0=[])\n",
    "        yp_cv[test_ind] = predfcn(b, df_test, xname)# **param) # multRegPredict(b,D,xname)\n",
    "        \n",
    "\n",
    "    # TSS\n",
    "    TSS = sum((y - y.mean())**2)\n",
    "\n",
    "    # cross validated RSS\n",
    "    RSScv = sum((y - yp_cv)**2)\n",
    "\n",
    "    # cross validated R2\n",
    "    R2cv = 1-RSScv/TSS\n",
    "\n",
    "    # fit and predict\n",
    "    yp = predfcn(b0, D, xname) # **param)\n",
    "\n",
    "    # \n",
    "    TSS = sum((y-y.mean())**2)\n",
    "    RSS = sum((y-yp)**2)\n",
    "    R2  = 1-RSS/TSS\n",
    "    \n",
    "    return R2cv, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R2 is 0.2789972631727561\n",
      "The R2 is 0.3560741562766846\n"
     ]
    }
   ],
   "source": [
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dSmoke\", \"dOak\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"The cross-validated R2 is\", R2cv)\n",
    "print(\"The R2 is\", R2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2.2 ( / 15 pts)\n",
    "Using the R2cv from the 20-fold crossvalidation, determine the best predictive model for birthweight using the following candidate variables \n",
    "\n",
    "- age of mom\n",
    "- smoker (dummy coded) \n",
    "- gestation \n",
    "- parity \n",
    "\n",
    "Start with the R2cv for the full model (Question 2.1)and use backwards step-wise regression to find the best model (the model that increases R2cv the most). Show all steps of your selection procedure. Report the formula of your best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated R2 is 0.2789972631727561\n",
      "\n",
      "NO AGE: The cross-validated R2 is 0.2873106969712439\n",
      "NO SMOKE: The cross-validated R2 is 0.1467521993404235\n",
      "NO OAK: The cross-validated R2 is 0.2936324987336909\n",
      "NO GESTATION: The cross-validated R2 is 0.11845001052539939\n",
      "\n",
      "Continuing with no Oak...\n",
      "NO AGE: The cross-validated R2 is 0.30136911537002453\n",
      "NO SMOKE: The cross-validated R2 is 0.17090307589581877\n",
      "NO GESTATION: The cross-validated R2 is 0.13457032967955462\n",
      "\n",
      "Continuing with no Oak and no age...\n",
      "NO SMOKE: The cross-validated R2 is 0.18436965020621765\n",
      "NO GESTATION: The cross-validated R2 is 0.14931498558437195\n",
      "\n",
      "The model no longer improves. The best model contains information on smoke and gestation.\n",
      "The formula contains the coefficients [-0.96184215 -1.01438409  0.03178096]\n"
     ]
    }
   ],
   "source": [
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dSmoke\", \"dOak\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"dSmoke\", \"dOak\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"\\nNO AGE: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dOak\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO SMOKE: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dSmoke\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO OAK: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dSmoke\", \"dOak\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO GESTATION: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "print(\"\\nContinuing with no Oak...\")\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"dSmoke\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO AGE: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO SMOKE: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"age\", \"dSmoke\",], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO GESTATION: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "print(\"\\nContinuing with no Oak and no age...\")\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"gestation\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO SMOKE: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVmultReg(df, y = df[\"weight\"], xname = [\"dSmoke\"], K = 20, fitfcn = multRegFit, param = {}, predfcn = multRegPredict)\n",
    "print(\"NO GESTATION: The cross-validated R2 is\", R2cv)\n",
    "\n",
    "print(\"\\nThe model no longer improves. The best model contains information on smoke and gestation.\")\n",
    "\n",
    "R2, b = multRegFit(df,y = df[\"weight\"], xname=[\"dSmoke\", \"gestation\"],figure=1,b0=[])\n",
    "print(\"The formula contains the coefficients\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Implement regularilzed regression to build a better predictive model (/35pts)\n",
    "In this task you will implement regularized regression to try to build a better predictive model for the birthweight of data. \n",
    "Like in Task 2, we will consider the following explanatory variables:\n",
    "\n",
    "- age of the mother \n",
    "- smoker (dummy coded) \n",
    "- birth occurred in Oakland? \n",
    "- gestation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.1: Z-standardize the regressors (/8pts)\n",
    "Write a function `zstandardize`, which takes as an input a pandas series or ndarray \n",
    "and returns a z-standardized version of the data \n",
    "\n",
    "Use the function to z-standardize the columns age,gestation,parity, and smokeDummy. \n",
    "\n",
    "Create new columns in the data frame called ageZ,gestationZ,parityZ, and smokeDummyZ.\n",
    "\n",
    "Check that the mean of the new variables in very close to and the std very close to 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zstandardize(inp): # takes all b values \n",
    "    inpMean = inp.mean()\n",
    "    inpSD = inp.std()\n",
    "    z = np.zeros(len(inp))\n",
    "    z = (inp - inpMean) / inpSD\n",
    "    \n",
    "     #z = inp - mean / SD\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age... Mean: -1.7930101847696278e-16 \t\tSD: 0.9999999999999999\n",
      "Smoke... Mean: 6.661338147750939e-18 \t\tSD: 0.9999999999999987\n",
      "Gestation... Mean: -2.369215934550084e-15 \tSD: 1.0\n",
      "Parity... Mean: -6.439293542825907e-17 \tSD: 0.9999999999999997\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>smoke</th>\n",
       "      <th>hospital</th>\n",
       "      <th>gestation</th>\n",
       "      <th>parity</th>\n",
       "      <th>weight</th>\n",
       "      <th>complication</th>\n",
       "      <th>dSmoke</th>\n",
       "      <th>dSF</th>\n",
       "      <th>dRich</th>\n",
       "      <th>dOak</th>\n",
       "      <th>dSJ</th>\n",
       "      <th>zAge</th>\n",
       "      <th>zDSmoke</th>\n",
       "      <th>zGestation</th>\n",
       "      <th>zParity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.945386</td>\n",
       "      <td>smoker</td>\n",
       "      <td>WalnutCreek</td>\n",
       "      <td>259.984898</td>\n",
       "      <td>1</td>\n",
       "      <td>6.154760</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.057013</td>\n",
       "      <td>2.279803</td>\n",
       "      <td>-0.823657</td>\n",
       "      <td>1.484435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37.369146</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanFrancisco</td>\n",
       "      <td>279.583370</td>\n",
       "      <td>0</td>\n",
       "      <td>6.746684</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.094299</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>0.615303</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.932707</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>287.107287</td>\n",
       "      <td>0</td>\n",
       "      <td>9.150785</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761300</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>1.167725</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.791652</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>270.374191</td>\n",
       "      <td>0</td>\n",
       "      <td>7.023815</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742021</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>-0.060854</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.950210</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>245.130005</td>\n",
       "      <td>0</td>\n",
       "      <td>5.861300</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.720412</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>-1.914335</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>17.535064</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.054332</td>\n",
       "      <td>1</td>\n",
       "      <td>6.816188</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.616510</td>\n",
       "      <td>2.279803</td>\n",
       "      <td>-0.524871</td>\n",
       "      <td>1.484435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>36.919301</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>249.503172</td>\n",
       "      <td>0</td>\n",
       "      <td>6.355362</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.032816</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>-1.593248</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>29.618348</td>\n",
       "      <td>smoker</td>\n",
       "      <td>Richmond</td>\n",
       "      <td>264.715985</td>\n",
       "      <td>1</td>\n",
       "      <td>6.102431</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034964</td>\n",
       "      <td>2.279803</td>\n",
       "      <td>-0.476291</td>\n",
       "      <td>1.484435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>22.833492</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>SanJose</td>\n",
       "      <td>288.755560</td>\n",
       "      <td>0</td>\n",
       "      <td>6.926468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.892351</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>1.288745</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>26.797815</td>\n",
       "      <td>non-smoker</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>286.339453</td>\n",
       "      <td>0</td>\n",
       "      <td>10.115025</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.350531</td>\n",
       "      <td>-0.434248</td>\n",
       "      <td>1.111349</td>\n",
       "      <td>-0.666920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       smoke      hospital   gestation  parity     weight  \\\n",
       "0   28.945386      smoker   WalnutCreek  259.984898       1   6.154760   \n",
       "1   37.369146  non-smoker  SanFrancisco  279.583370       0   6.746684   \n",
       "2   34.932707  non-smoker      Richmond  287.107287       0   9.150785   \n",
       "3   34.791652  non-smoker       Oakland  270.374191       0   7.023815   \n",
       "4   41.950210  non-smoker       SanJose  245.130005       0   5.861300   \n",
       "..        ...         ...           ...         ...     ...        ...   \n",
       "95  17.535064      smoker      Richmond  264.054332       1   6.816188   \n",
       "96  36.919301  non-smoker      Richmond  249.503172       0   6.355362   \n",
       "97  29.618348      smoker      Richmond  264.715985       1   6.102431   \n",
       "98  22.833492  non-smoker       SanJose  288.755560       0   6.926468   \n",
       "99  26.797815  non-smoker       Oakland  286.339453       0  10.115025   \n",
       "\n",
       "    complication  dSmoke  dSF  dRich  dOak  dSJ      zAge   zDSmoke  \\\n",
       "0              1     1.0  0.0    0.0   0.0  0.0 -0.057013  2.279803   \n",
       "1              1     0.0  1.0    0.0   0.0  0.0  1.094299 -0.434248   \n",
       "2              0     0.0  0.0    1.0   0.0  0.0  0.761300 -0.434248   \n",
       "3              0     0.0  0.0    0.0   1.0  0.0  0.742021 -0.434248   \n",
       "4              0     0.0  0.0    0.0   0.0  1.0  1.720412 -0.434248   \n",
       "..           ...     ...  ...    ...   ...  ...       ...       ...   \n",
       "95             1     1.0  0.0    1.0   0.0  0.0 -1.616510  2.279803   \n",
       "96             0     0.0  0.0    1.0   0.0  0.0  1.032816 -0.434248   \n",
       "97             0     1.0  0.0    1.0   0.0  0.0  0.034964  2.279803   \n",
       "98             1     0.0  0.0    0.0   0.0  1.0 -0.892351 -0.434248   \n",
       "99             0     0.0  0.0    0.0   1.0  0.0 -0.350531 -0.434248   \n",
       "\n",
       "    zGestation   zParity  \n",
       "0    -0.823657  1.484435  \n",
       "1     0.615303 -0.666920  \n",
       "2     1.167725 -0.666920  \n",
       "3    -0.060854 -0.666920  \n",
       "4    -1.914335 -0.666920  \n",
       "..         ...       ...  \n",
       "95   -0.524871  1.484435  \n",
       "96   -1.593248 -0.666920  \n",
       "97   -0.476291  1.484435  \n",
       "98    1.288745 -0.666920  \n",
       "99    1.111349 -0.666920  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zAge = zstandardize(df[\"age\"])\n",
    "print(\"Age... Mean:\", zAge.mean(), \"\\t\\tSD:\", zAge.std())\n",
    "df['zAge']  = zAge\n",
    "\n",
    "zDSmoke = zstandardize(df[\"dSmoke\"])\n",
    "print(\"Smoke... Mean:\", zDSmoke.mean(), \"\\t\\tSD:\", zDSmoke.std())\n",
    "df['zDSmoke']  = zDSmoke\n",
    "\n",
    "zGestation = zstandardize(df[\"gestation\"])\n",
    "print(\"Gestation... Mean:\", zGestation.mean(), \"\\tSD:\", zGestation.std())\n",
    "df['zGestation']  = zGestation\n",
    "\n",
    "zParity = zstandardize(df[\"parity\"])\n",
    "print(\"Parity... Mean:\", zParity.mean(), \"\\tSD:\", zParity.std())\n",
    "df['zParity']  = zParity\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.2 Implement Ridge regression (L2 regularized regression) (/17pts)\n",
    "\n",
    "To implement ridge regression you need to modify two functions, the most important being the loss function. \n",
    "Make a copy of the function `multRegLossRSS` from assigment 10. \n",
    "Rename it to `ridgeLoss`. Give the function an additional input parameter, namely alpha. Give this a default value of 1.0. \n",
    "\n",
    "Change the loss and the gradient to take into account the regularization. \n",
    "\n",
    "**Note that we are not regularizing the intercept regressor (b0)**\n",
    "\n",
    "Overall the function should take the following input arguments:\n",
    "\n",
    "    Args:\n",
    "        b (nd.array): Array of regression coefficients - first is intercept \n",
    "        D (pd.DataFrame): Pandas data frame with explanatory variables\n",
    "        y (ndarray): Dependent variable \n",
    "        xname (list): List of strings with names of explanatory variables\n",
    "        alpha (float): Regularization parameter \n",
    "\n",
    "    Returns:\n",
    "        loss: Current loss\n",
    "        grad: gradient of loss function in respect to parameters  \n",
    "\n",
    "Then make a copy of `multRegFit` from the last homework and rename it to `ridgeFit`. \n",
    "Again, you need to add an additional input parameter (alpha) to the function. \n",
    "Alpha needs to be passed to your loss function (`ridgeLoss`) when you call so.minimize: \n",
    "\n",
    "`so.minimize(ridgeLoss,b0,args=(D,y,xname,alpha),jac=True)`\n",
    "\n",
    "You need to take care when you calculate R2 of the fit - Since ridgeLoss does not return the \n",
    "residual-sum-of-squares, you need to use the appropriate function to calculate the RSS.\n",
    "\n",
    "To test your function:\n",
    "* Use it to fit a model that explains weight with the explanatory variables `['ageZ','smokeDummyZ','gestationZ','parityZ']`. Note: use the zstandardized version of the variables.  \n",
    "* Do the fit setting `alpha=0` and `alpha=8`, and report both R2 and the regression coefficients (b)\n",
    "* Compare the R2 between the two settings of alpha. Also compare to the one found for normal multiple regression (Question 2.1). What do you see and why?\n",
    "* Compare the regression weights (b) between the two settings of alpha. which regression weights changed and why? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridgeLoss(b,D,y,xname, a = 1):\n",
    "    \n",
    "    predY = multRegPredict(b,D,xname)\n",
    "    res = y-predY\n",
    "    rss = sum(res**2)\n",
    "    grad=np.zeros(len(b))\n",
    "    grad[0]=-2*np.sum(res)\n",
    "    \n",
    "    loss = rss + a*(np.sum(b[1:]**2))\n",
    "    \n",
    "    for i in range(len(xname)):\n",
    "        grad[i+1]=-2*np.sum(D[xname[i]]*res) + (2 * a * b[i+1])\n",
    "        \n",
    "    return (loss,grad)\n",
    "\n",
    "def ridgeFit(D,y,xname=[], a = 1, figure=0,b0=[]):\n",
    "    \n",
    "    k=len(xname)+1\n",
    "    if (len(b0)!=k):\n",
    "        b0=np.zeros((k,))\n",
    "    RES = so.minimize(ridgeLoss,b0,args=(D,y,xname,a),jac=True)\n",
    "    b=RES.x # Results\n",
    "    res = y-np.mean(y)\n",
    "    TSS = sum(res**2)\n",
    "    \n",
    "    predY = multRegPredict(b,D,xname)\n",
    "    res = y-predY\n",
    "    RSS = sum(res**2)\n",
    "    \n",
    "    #RSS,deriv = multRegLossRSS(b,D,y,xname)\n",
    "    R2 = 1-RSS/TSS \n",
    "    if (k==2 and figure==1):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        ax.scatter(D[xname[0]],y)\n",
    "        xRange=[min(D[xname[0]]),max(D[xname[0]])]\n",
    "        xp=np.arange(xRange[0],xRange[1],(xRange[1]-xRange[0])/50)\n",
    "        yp=b[0]+b[1]*xp\n",
    "        ax.plot(xp,yp,'r-')\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "    return (R2,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a = 0 R2 is 0.3503171176870481 and b is [ 7.49494802e+00 -1.04180250e-01 -3.82511915e-01  4.33892437e-01\n",
      "  4.17899298e-03]\n",
      "With a = 8 R2 is 0.3487574657496001 and b is [ 7.49494804e+00 -9.43223955e-02 -3.57549042e-01  4.04957781e-01\n",
      "  3.18959013e-03]\n"
     ]
    }
   ],
   "source": [
    "R2, b = ridgeFit(df,y = df[\"weight\"],xname= [\"zAge\", \"zDSmoke\", \"zGestation\", \"zParity\"],figure=0,b0=[], a = 0)\n",
    "print(\"With a = 0 R2 is\", R2, \"and b is\", b)\n",
    "\n",
    "R2, b = ridgeFit(df,y = df[\"weight\"],xname= [\"zAge\", \"zDSmoke\", \"zGestation\", \"zParity\"],figure=0,b0=[], a = 8)\n",
    "print(\"With a = 8 R2 is\", R2, \"and b is\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written:\n",
    "2.1 refresher:\n",
    "[\"age\", \"dSmoke\", \"dOak\", \"gestation\"]\n",
    "The R2 is 0.3560741562766846\n",
    "\n",
    "\n",
    "The R2 in 2.1 and 3.2 with a = 0 are very similar despite using different variables. This is likely due to one of the variables being accounted for already by another. The difference in R2 is closer between the 2 a values than I expected. There is very minimal difference despite some coefficients going through larger changes. All regression weights changed to some extent. I noticed that the variables that make up the best model from 2.2 experience less change on their b values. Larger coefficients are penalized more, changing the estimated influence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.3: Crossvalidate Ridge regression (10pts)\n",
    "Copy your function `KfoldCVmultReg` from Question 2.1, rename it to `KfoldCVridge`, and modify it to work with Ridge regression. \n",
    "That means it needs to take an additional input parameter `alpha` that it passes on to the fitting function. \n",
    "\n",
    "To calculate the R2 and R2cv for the model of `weight` using the explanatory variables `['ageZ','smokeDummyZ','gestationZ','parityZ']`. Like in question 3.2, use the standardized versions of the variables and try both the setting `alpha=0` and `alpha=8`. \n",
    "\n",
    "How to the R2 and R2cv values compare between the two settings of alpha? Do you get better predictive performance than the reduced model that you found using feature selection (Question 2.2)?\n",
    "\n",
    "\n",
    "*Note: If you want, play a bit with the regularization parameter to see if you can find a better setting. What happens when you make `alpha` very large (i.e. 1000)? (this is optional, but educational)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KfoldCVridge(D, y, xname, K = 20, fitfcn = ridgeFit, param={}, predfcn = multRegPredict, a = 1):\n",
    "\n",
    "    # first create an array that represent the index \n",
    "    ind = np.arange(len(df.index))\n",
    "    \n",
    "    yp_cv = np.zeros(len(df.index))\n",
    "\n",
    "    # use np.array_split to generate indices for folds\n",
    "    folds = np.array_split(ind, K)\n",
    "    \n",
    "    N = len(folds)\n",
    "    \n",
    "    r,b0 = fitfcn(D,y,xname,a,**param)\n",
    "    \n",
    "    for f in np.arange(N): \n",
    "        folds_cp = folds.copy() # creating a copy of the folds array\n",
    "        test_ind = folds[f] # get the indices for test set\n",
    "        df_test  = df.loc[test_ind] # set one fold aside for testing\n",
    "\n",
    "\n",
    "        del folds_cp[f]        # delete the test set indices\n",
    "        train_ind = np.concatenate(folds_cp, axis = 0) # concatenate all the remaining indices into 1 array\n",
    "        df_train  = df.loc[train_ind]\n",
    "        ytrain = y.loc[train_ind]\n",
    "        \n",
    "        r,b = fitfcn(df_train,ytrain,xname,a, **param) # multRegFit(D,y,xname=[],figure=0,b0=[])\n",
    "        yp_cv[test_ind] = predfcn(b, df_test, xname)# **param) # multRegPredict(b,D,xname)\n",
    "        \n",
    "\n",
    "    # TSS\n",
    "    TSS = sum((y - y.mean())**2)\n",
    "\n",
    "    # cross validated RSS\n",
    "    RSScv = sum((y - yp_cv)**2)\n",
    "\n",
    "    # cross validated R2\n",
    "    R2cv = 1-RSScv/TSS\n",
    "\n",
    "    # fit and predict\n",
    "    yp = predfcn(b0, D, xname) # **param)\n",
    "\n",
    "    # \n",
    "    TSS = sum((y-y.mean())**2)\n",
    "    RSS = sum((y-yp)**2)\n",
    "    R2  = 1-RSS/TSS\n",
    "    \n",
    "    return R2cv, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a = 0 R2 is 0.3503171176870481 and R2cv is 0.2881957500610136\n",
      "With a = 8 R2 is 0.3487574657496001 and R2cv is 0.29024710723150904\n",
      "With a = 1000 R2 is 0.06752841175715196 and R2cv is 0.03556416707386845\n"
     ]
    }
   ],
   "source": [
    "R2cv, R2 = KfoldCVridge(df, df[\"weight\"], xname = [\"zAge\", \"zDSmoke\", \"zGestation\", \"zParity\"], K = 20, fitfcn = ridgeFit, param={}, predfcn = multRegPredict, a = 0)\n",
    "print(\"With a = 0 R2 is\", R2, \"and R2cv is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVridge(df, df[\"weight\"], xname = [\"zAge\", \"zDSmoke\", \"zGestation\", \"zParity\"], K = 20, fitfcn = ridgeFit, param={}, predfcn = multRegPredict, a = 8)\n",
    "print(\"With a = 8 R2 is\", R2, \"and R2cv is\", R2cv)\n",
    "\n",
    "R2cv, R2 = KfoldCVridge(df, df[\"weight\"], xname = [\"zAge\", \"zDSmoke\", \"zGestation\", \"zParity\"], K = 20, fitfcn = ridgeFit, param={}, predfcn = multRegPredict, a = 1000)\n",
    "print(\"With a = 1000 R2 is\", R2, \"and R2cv is\", R2cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R2 and R2cv values between the 0 and 8 settings of alpha are actually a lot closer in value than I thought they would be. Seeing 0.01 differences in each. This model does not provide better predictive performance than the reduced model as it has an R2cv of 0.301369. After some experimentation it appears that a = 8 yeilds the highest R2cv. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Use logistic regression to predict complications \n",
    "In this task you will create and test a logistic regression model that predicts the presence of a complication in the first three month (0: no complication, 1: complication). \n",
    "\n",
    "** Task 4 of the Homework does not have to be handed in and will not be graded! It is only added here to provide additional preparation and practice for you for the final. So if you are short on time, leave these questions open and solve them when you practice for the final.**\n",
    "\n",
    "### Question 4.1: Improving your logistic regression model code\n",
    "Improve your code for logisitic regression in two ways: \n",
    "\n",
    "1. prevent log(0) errors by making sure that your predicted value never is smaller than 1e-20 or larger than 1-1e-20. (tip you can use the numpy function `clip`)\n",
    "\n",
    "2. Let logisticRegFit take an additional input parameter, telling it whether it should plot a figure or not (figure=1) \n",
    "\n",
    "3. Let logisticRegFit take an additional input parameter, specifying the starting value for the parameters (b0=[]). If b0 is empty, the function should start with a vector off all zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.2: Crossvalidation of logistic models\n",
    "Modify the KfoldCVmultReg function to make it work for logistic regression. As before, use K-fold crossvalidation. The main changes are that \n",
    "- you need to use logisticRegFit and logisticRegPredict as fitfcn and predictfcn respectively. \n",
    "- instead of the crossvalidated R2, your function should return the crossvalidated log-likelihood and non-crossvalidated log-likelihood. \n",
    "\n",
    "Using your function, calculate the the difference in crossvalidated log-likelihood for the model that predicts complications with an intercept only (b0) and a model that predicts complications with an intercept and smokeDummy. \n",
    "From the difference, report the Bayes-Factor between the two models. What do you conclude? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.3:\n",
    "Compare the model that uses only smoking (and intercept) as explanatory variable to one that uses additionally (to intercept and smoking) the weight of the baby at birth, age of the mom, or both. Calculate crossvalidated Log-likelihood, which one is the best model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.4 : \n",
    "In the model (['smokeDummy','weight']), how do each of the explanatory variables contribute to the chance of complication? That is, for each variable, would an increase an the variable lead to an increased or decreased probability of a complication? In terms of risk of complications, how many pounds of extra weight can make up for having a smoking mother?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d597f4c481aa0f25dceb95d2a0067e73c0966dcbd003d741d821a7208527ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
